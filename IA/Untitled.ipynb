{"cells":[{"metadata":{},"cell_type":"markdown","source":"Presentado por:<br>\nDavid Crespo <br>\nCristina Mejia <br>\nMelissa Fuentes <br>"},{"metadata":{},"cell_type":"markdown","source":"El objeto de este proyecto es alicar los conceptos de aprendizaje de máquina vistos en el curso. Se hará el entrenamiento de modelos de clasificación usando árboles de decisión, naive bayes y redes neuronales para resolver un problema de clasificación a partir de un conjunto de datos relacionados a enfermedades del corazón.\n"},{"metadata":{},"cell_type":"markdown","source":"Primero se importan las librerías:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport sklearn\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ahora cargamos los dos archivos de conjuntos de datos."},{"metadata":{"trusted":true},"cell_type":"code","source":"heartDataCSV = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\n#heartDiseaseData = pd.read_csv(\"HeartDisease.csv\")\n\nprint(heartDataCSV.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se convierten los datos en un dataFrame de Pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData = pd.DataFrame(heartDataCSV)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Histogramas"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"\n\nheartData[\"age\"].hist(figsize=(6,3))\nplt.title('Age')\nplt.show()\nheartData[\"trestbps\"].hist(figsize=(6,3))\nplt.title('Trestbps')\nplt.show()\nheartData[\"chol\"].hist(figsize=(6,3))\nplt.title('Chol')\nplt.show()\nheartData[\"thalach\"].hist(figsize=(6,3))\nplt.title('Thalach')\nplt.show()\nheartData[\"oldpeak\"].hist(figsize=(6,3))\nplt.title('Oldpeak')\nplt.show()\nheartData[\"ca\"].hist(figsize=(6,3))\nplt.title('Ca')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sums = heartData.sex.sum()\nprint(sums)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Diagramas de pastel"},{"metadata":{"trusted":true},"cell_type":"code","source":"heartData.restecg.groupby(heartData.sex).sum().plot(kind = 'pie')\nplt.axis('equal')\nplt.ylabel('genre')\nplt.show()\nheartData.restecg.groupby(heartData.fbs).sum().plot(kind = 'pie')\nplt.axis('equal')\nplt.ylabel('fbs')\nplt.show()\nheartData.sex.groupby(heartData.restecg).sum().plot(kind = 'pie')\nplt.axis('equal')\nplt.ylabel('restecg')\nplt.show()\nheartData.restecg.groupby(heartData.exang).sum().plot(kind = 'pie')\nplt.axis('equal')\nplt.ylabel('exang')\nplt.show()\nheartData.restecg.groupby(heartData.thal).sum().plot(kind = 'pie')\nplt.axis('equal')\nplt.ylabel('thal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Organización de conjunto de datos**\n\nA continuación se analaizará el conjunto de datos para considerar si hace falta completar o remover elementos faltantes o nulos"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Punto 5 en el que miramos si hay valores nulos o faltantes en nuestro conjunto de datos\nheartDataCSV = pd.read_csv(\"../input/heart-disease-uci/heart.csv\")\nx = pd.notnull(heartDataCSV)  \nheartDataCSV[x]\n\n#Gracias a la función notnull, podemos mostrar todo nuestro conjunto de datos cuya celda sea distinta de NaN, y como nos retorna las 303 filas en total con las 14 columnas, podemos decir que nuestro conjunto de datos no tenia regitros faltantes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nGracias a la función notnull, podemos mostrar todo nuestro conjunto de datos cuya celda sea distinta de NaN, y como nos retorna las 303 filas en total con las 14 columnas, podemos decir que nuestro conjunto de datos no tenia regitros faltantes, por lo que concluimos que no hubo necesidad de realizar ninguna modificación al conjunto de datos.\n\nAhora a continuación partiremos los datos en dos grupos. El 80% de ellos para entrenamiento y el 20% para pruebas.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Create a new array with the added features: features_two\nvariables = heartData[['age','sex','cp','trestbps', 'chol', 'fbs', 'restecg',\n                      'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']].values\ntarget = heartData['target'].values\n\n\n# Split the data into train and test\ntrainX, testX, trainY, testY = train_test_split(variables, target, test_size=0.2)\nprint(trainX.shape, trainY.shape)\nprint(testX.shape, testY.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Entrenamos un modelo de Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\n\n\ngnb = GaussianNB()\n\nmodeloBayes = gnb.fit(trainX, trainY)\n\n#Mostramos el score del nuevo arbol de desición \nprint(\"Exactitud en el entrenamiento\")\nprint(modeloBayes.score(trainX, trainY))\n\nprint(\"Exactitud en la prueba\")\nprint(modeloBayes.score(testX, testY))\n\n#Mostramos la matriz de confusión para el modelo \nconfusion_matrix(modeloBayes.predict(testX), testY)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Árboles de decisión**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Arbolito bonito\n\narbol = DecisionTreeClassifier(max_depth = 4, min_samples_split =4)\narbol.fit(trainX, trainY)\n\n#Print the score on the train data\nprint(arbol.score(trainX, trainY))\n#Print the score on the test data\nprint(arbol.score(testX, testY))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"export_graphviz(arbol, out_file='arbol.dot',impurity=False, filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydotplus\nfrom IPython.display import Image\n\npydot_graph = pydotplus.graph_from_dot_file(\"arbol.dot\")\nImage(pydot_graph.create_png())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Matriz de confusión\nfrom sklearn.metrics import confusion_matrix\n\nconfusion_matrix(arbol.predict(testX), testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Red neuronal**\n\nUtilizaremos numpy para el manejo de arrays de Keras, se importa el  modelo Sequential y la capa Dense\n\nCreamos los arrays de entrada seran trainX y trainY"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(16, input_dim=13, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"se crea un modelo vació de tipo Sequential, esto quiere decir que crearemos una serie de capas\n\nCon esto indicamos el tipo de pérdida (loss) que utilizaremos, el «optimizador» de los pesos de las conexiones de las neuronas y las métricas que queremos obtener.\n\nIndicamos con model.fit() las entradas y sus salidas y la cantidad de iteraciones de "},{"metadata":{"trusted":true},"cell_type":"code","source":"\n \nmodel.compile(loss='mean_squared_error',\n              optimizer='adam',\n              metrics=['binary_accuracy'])\n \nmodel.fit(trainX, trainY, epochs=1000)\n \n# evaluamos el modelo\nscores = model.evaluate(testX, testY)\n \nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\nprint (model.evaluate(trainX,trainY))\n\n#Mostramos la matriz de confusión para el modelo \nconfusion_matrix(model.predict_classes(testX), testY)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"al finalizar, los resultados permite ver el nivel de acierto de la primera y segunda iteración \n\nLuego en la «epoch» se hacen los ajustes correspondientes a la red\n\n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.15+"}},"nbformat":4,"nbformat_minor":1}
